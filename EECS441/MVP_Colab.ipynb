{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3e2UeYAQZ7LU"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from google.colab import drive\n",
        "import tempfile\n",
        "\n",
        "tmpdir = tempfile.mkdtemp()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Commented out lines import tsb.zip into google colab environment\n",
        "# Need to upload the file to your google drive, below file path is in the root directory\n",
        "\n",
        "# mount drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# used for unzip files\n",
        "!unzip gdrive/My\\ Drive/ava.zip\n",
        "\n",
        "\n",
        "# path to a image: tsb/basedata/training/bad-image/2.jpg\n",
        "img = tf.keras.preprocessing.image.load_img('/content/ava/Training/training_bad_image/2.jpg')\n",
        "# save the image to the current directory\n",
        "img.save('2.jpg')\n",
        "\n",
        "cv2.imread('2.jpg')\n",
        "train = ImageDataGenerator(rescale=1/255)\n",
        "validation = ImageDataGenerator(rescale=1/255)"
      ],
      "metadata": {
        "id": "bIagQRanaDMC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "8bf6201f-703e-49a0-8ff6-44ab8c53d3cc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Archive:  gdrive/My Drive/ava.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of gdrive/My Drive/ava.zip or\n",
            "        gdrive/My Drive/ava.zip.zip, and cannot find gdrive/My Drive/ava.zip.ZIP, period.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-1898186e7b6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# path to a image: tsb/basedata/training/bad-image/2.jpg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/ava/Training/training_bad_image/2.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# save the image to the current directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m       \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m       \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/ava/Training/training_bad_image/2.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = train.flow_from_directory('/content/ava/basedata/training',\n",
        "                                            target_size=(200,200),\n",
        "                                            batch_size=64,\n",
        "                                            class_mode='binary')\n",
        "\n",
        "validation_dataset = train.flow_from_directory('/content/ava/basedata/Validating',\n",
        "                                            target_size=(200,200),\n",
        "                                            batch_size=64,\n",
        "                                            class_mode='binary')"
      ],
      "metadata": {
        "id": "CQIcqGwSaFQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset.class_indices\n"
      ],
      "metadata": {
        "id": "kDxmbdQdaK2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(200,200,3)),\n",
        "                                      tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                      # The second convolution\n",
        "                                        tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
        "                                        tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                        # The third convolution\n",
        "                                        tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "                                        tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                        # The fourth convolution\n",
        "                                        tf.keras.layers.Flatten(), \n",
        "                                        tf.keras.layers.Dense(512,activation='relu'),\n",
        "                                        tf.keras.layers.Dense(1,activation='sigmoid')])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "pzD2IkDcaO41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "                optimizer=RMSprop(lr=0.001),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Wd12EhWlaQjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(training_dataset,\n",
        "            steps_per_epoch=19,\n",
        "            epochs=10,\n",
        "            validation_data=validation_dataset)"
      ],
      "metadata": {
        "id": "rccnrWpPaSZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = '/content/ava/basedata/testing'\n",
        "for img in os.listdir(dir_path):\n",
        "    img = tf.keras.preprocessing.image.load_img(dir_path + '/' + img, target_size=(200,200))\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    X = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    X = np.expand_dims(X, axis=0)\n",
        "\n",
        "    images = np.vstack([X])\n",
        "    classes = model.predict(images, batch_size=10)\n",
        "    print(classes[0])\n",
        "    if classes[0]==0:\n",
        "        print('bad photo')\n",
        "    else:\n",
        "        print('good photo')"
      ],
      "metadata": {
        "id": "IgxQiB_EaUhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the image in the custom-ava-downloader/validation_image folder with the model\n",
        "# print the prediction result\n",
        "# if the prediction result is 1, then the image is a good image\n",
        "# if the prediction result is 0, then the image is a bad image\n",
        "import numpy as np\n",
        "import json\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# read JSON file, for comparsion later on with prediction result\n",
        "with open('/ava/image_data.json') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "# loop through the images in the custom-ava-downloader/validation_image folder and predict the image\n",
        "for image_name in os.listdir('ava/Testing'):\n",
        "\n",
        "    # resize this image \n",
        "    test_image = image.load_img('ava/Testing/' + image_name, target_size = (200, 200))\n",
        "\n",
        "    # print the image \n",
        "    plt.imshow(test_image)\n",
        "    plt.show()\n",
        "\n",
        "    # convert the image to an array\n",
        "    test_image = image.img_to_array(test_image)\n",
        "\n",
        "    # expand the dimension of the image\n",
        "    test_image = np.expand_dims(test_image, axis = 0)\n",
        "\n",
        "    # predict the image\n",
        "    result = model.predict(test_image)\n",
        "    if result[0][0] == 1:\n",
        "        prediction = 'good image'\n",
        "    else:\n",
        "        prediction = 'bad image'\n",
        "    print(image_name + \" is a \" + prediction + \" with a prediction result of \" + str(result[0][0]))"
      ],
      "metadata": {
        "id": "sYbTE7jaihNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "MUkrukSkkiZn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}